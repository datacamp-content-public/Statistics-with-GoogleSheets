---
title: Insert title here
key: 07638757a1c9f5b135cdc134885d9201

---
## Two Sample t-test

```yaml
type: "TitleSlide"
key: "d68a5e80b5"
```

`@lower_third`

name: Jim Hunter
title: Retrovirology Laboratory, UNIFESP Brazil


`@script`
Let's look at how statistics can help us resolve a simple question. We have a sample of 500 loans granted by the LendingClub. The dataset is one of the open source datasets that come from Kaggle.


---
## The Question

```yaml
type: "FullSlide"
key: "9a024e6767"
```

`@part1`
- Do applicants with a bad loan evaluation pay a higher interest rate?


`@script`
The question here is will I pay a higher interest rate for interest rate if my loan grade is below a certain level.


---
## The Data

```yaml
type: "FullImageSlide"
key: "5026ba378a"
center_content: false
```

`@part1`
![](https://assets.datacamp.com/production/repositories/3614/datasets/6140aa2725b31ff4ce4638f2771e232cb86e5aa3/slide data.png)


`@script`
Here's our data. I have broken the 500 cases in our sample into "high" and "low" scores. Each case is a loan and our data shows the interest rate on that loan.


---
## Basic Statistics on Interest Rates

```yaml
type: "FullSlide"
key: "656fc03da6"
```

`@part1`
![](https://assets.datacamp.com/production/repositories/3614/datasets/d4eafbd1b3a1847f9b8ed1c93fdbdc05886de7cc/slide setup.png)


`@script`
Our first step in answering this question is to look at the data. What is the mean of interest rates for each type of rating? How many cases fall into each category?
We do this with basic statistics functions. But, first we set up the sheet with names. I have named the set of "High" grade interest rates with the name "hi-grade" and the "Low" cases with "lo-grade". Now, let's set up an area with the titles for the counts, etc. as we can see on the slide.


---
## Exploratory Stats

```yaml
type: "FullSlide"
key: "10e5d6df71"
```

`@part1`
- Counts: ```COUNT(hi_grade)``` 
- Mean:   ```AVERAGE(hi_grade)```
- Standard Deviation: ```STDEV(hi_grade)```


`@script`
Our 3 functions are COUNT, AVERAGE and STDEV. Now we can put formulas in the cells to the right of the names using the field names we created before. It certainly eases the process of writing formulas. No more A1:AA756 that no one can understand.


---
## Exploratory Formulas

```yaml
type: "FullImageSlide"
key: "c694288970"
```

`@part1`
![](https://assets.datacamp.com/production/repositories/3614/datasets/4d8570cc942b7aa01596d956fa364246af054f9b/slide explore new.png)


`@script`
The formulas are now in. And we have some results. I've also shown the formulas themselves off to the right of the values to help you with them. We can see that we have many more cases with high grades than with low grades and that the mean interest rate for high graded borrowers is 11.2% in contrast to 18.6%. So we can intuit that the difference between them will be statistically significant. 
But, let's ago ahead and prove it with the t.test function.


---
## What is a t-test?

```yaml
type: "FullImageSlide"
key: "d7dbea77bd"
```

`@part1`
- A means of evaluating difference between variables/groups
- Evaluate in terms of distribution of each group
- See if difference is statistically significant
- Large enough to pay attention


`@script`



---
## When Can We Use a t-Test?

```yaml
type: "FullSlide"
key: "ae81b0cdbb"
```

`@part1`
- Restrictions on use
- Data must be numeric
- Other methods for categorical variables
- Data should be normally distributed
- Large counts ok (sort of)


`@script`



---
## What the t-Test Does

```yaml
type: "TwoColumns"
key: "42fb0af8f8"
```

`@part1`
![](https://assets.datacamp.com/production/repositories/3614/datasets/8343f49184b58dcbf13d5c1e1ab33e914554a419/norm_hilo.png)


`@part2`
![](https://assets.datacamp.com/production/repositories/3614/datasets/2255169a743d5c0798c33c15400b46a3de1bdaba/int_rate_grade_densr.png)


`@script`



---
## t.test Function

```yaml
type: "FullSlide"
key: "ccaafd20f2"
```

`@part1`
- Null hypothesis: no difference between groups
- t.test Function: ```=T.TEST(hi_grade, lo_grade, tails, alternative)```
- Tails: 1 or 2
- Alternative:  1 if paired test, 2 if samples have equal variance, 3 if samples have unequal variances
-```t.test(hi_grade, lo_grade, 1, 3)```


`@script`
Working with the t.test function is a bit like reading the last chapter of a mystery novel first. You find out the final answer, but you don't know how you arrived at this point. We'll cover the missing parts of the t-test in the Exercises.
But, here we will discover what the probability is that there is no difference in interest rates between the high grade group and the low grade group. What we call the null hypothesis.
The function needs 4 arguments: the two subsets being compared, the number of tails that we will be testing against. We discussed this previously in speaking of distributions. The last argument has to do with the type of the test. If you are comparing paired data, you use the number 1. If the two samples are independent but have equal variances, you use the number 2, and otherwise you use number 3.


---
## t-test Executed

```yaml
type: "TwoRows"
key: "86e00d9656"
```

`@part1`
![](https://assets.datacamp.com/production/repositories/3614/datasets/a32756719c59aa430661b8012e484935e1d73dfa/slide t-test new.png)


`@part2`



`@script`
In our case, the variances are close but not equal, so we will stick with alternative number 3, the most conservative. When the function executes, it produces a probability called a "p-value", which we can see here on line 10 is very small, very small indeed. We are going to compare this value to a standard value called alpha, which we normally set at 0.05. Since this value is much smaller than 0.05, we conclude that we cannot accept the hypothesis that there is no difference. The difference we initially thought was there, is probably there. In the exercises, we'll do more with this and fill in some of the missing pieces. Time to do some coding ...


---
## t-test Executed

```yaml
type: "FullImageSlide"
key: "3565ee6042"
```

`@part1`
![](https://assets.datacamp.com/production/repositories/3614/datasets/a32756719c59aa430661b8012e484935e1d73dfa/slide t-test new.png)


`@script`
In our case, the variances are close but not equal, so we will stick with alternative number 3, the most conservative. When the function executes, it produces a probability called a "p-value", which we can see here on line 10 is very small, very small indeed. We are going to compare this value to a standard value called alpha, which we normally set at 0.05. Since this value is much smaller than 0.05, we conclude that we cannot accept the hypothesis that there is no difference. The difference we initially thought was there, is probably there. In the exercises, we'll do more with this and fill in some of the missing pieces. Time to do some coding ...


---
## Final Slide

```yaml
type: "FinalSlide"
key: "ff1cd7916b"
```

`@script`


